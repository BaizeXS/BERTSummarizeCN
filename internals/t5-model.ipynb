{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edefcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets evaluate peft accelerate gradio optimum sentencepiece \n",
    "%pip scikit-learn tensorboard nltk rouge rouge-chinese"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d4efd2c990f98",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 1: 导入前置依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T15:43:59.534032Z",
     "start_time": "2023-09-02T15:43:51.914908Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from rouge_chinese import Rouge\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aad6b05283e26a5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 2: 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b727d701195443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T15:44:33.562422Z",
     "start_time": "2023-09-02T15:44:28.035948Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Content', 'Keywords'],\n",
       "        num_rows: 6000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Content', 'Keywords'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取数据\n",
    "df = pd.read_csv('../data/keysum_data_A.csv')\n",
    "# 构建 DataFrame\n",
    "df = pd.DataFrame(df)\n",
    "# 构建数据集\n",
    "dataset = Dataset.from_pandas(df)\n",
    "# 划分数据集\n",
    "dataset = dataset.train_test_split(2000, seed=42)\n",
    "# 显示数据集\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "783d22dbea73d2f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T13:38:57.852309Z",
     "start_time": "2023-09-02T13:38:57.816905Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Content': '基于游程递归的连通区域标记算法。在研究已有算法的基础上,提出一种基于游程递归的标记算法,该算法可以对二值图像实现快速标记.顺序扫描图像,寻找未标记的游程,并递归搜索与之连通的游程,直到一个连通区域生成.在游程搜索过程中,在当前游程的相邻两行上,以其左端点为起始点分别向前向后进行连通游程的搜索;同时根据游程之间的位置关系对搜索策略进行优化,减少了重复搜索,提高了处理速度.该算法只需经过一次扫描图像,就能快速、准确地标记连通区域.在与已有算法的实验结果比较中,该算法具有较快的执行速度和较高的准确率,并且占用较少的内存,可以满足在施工现场中运动目标实时检测的需要. 基于游程递归的连通区域标记算法',\n",
       " 'Keywords': '运动目标; 连通区域标记; 二值图像'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d67bd869beb7e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 3: 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1edace403f6d38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T13:40:32.493291Z",
     "start_time": "2023-09-02T13:40:27.739410Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 设置 Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理函数\n",
    "# TODO: 改为传入Tokenizer\n",
    "def process_func(examples):\n",
    "    contents = [\"摘要生成: \\n\" + e for e in examples[\"Content\"]]\n",
    "    # 对输入(Content)进行 Tokenization\n",
    "    inputs = tokenizer(contents, max_length=512, truncation=True)\n",
    "    # 对输出(Keywords)进行 Tokenization\n",
    "    labels = tokenizer(text_target=examples[\"Keywords\"], max_length=64, truncation=True)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd5c7ee0427022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T13:40:34.527185Z",
     "start_time": "2023-09-02T13:40:34.231152Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 对数据集进行 Tokenization\n",
    "tokenized_dataset = dataset.map(process_func, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e18192159bf315",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T13:40:38.474078Z",
     "start_time": "2023-09-02T13:40:38.394076Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example\n",
    "print(tokenizer.decode(tokenized_dataset[\"train\"][0][\"input_ids\"]))\n",
    "print(tokenizer.decode(tokenized_dataset[\"train\"][0][\"labels\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff68088f485319f3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Step 4: 设置预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443ff5ccd80ba75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T13:40:52.207815Z",
     "start_time": "2023-09-02T13:40:45.523263Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 加载预训练模型\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Langboat/mengzi-t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81603df5e54fe7f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Step 5: 设置评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb15d9236de83f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T13:40:54.670343Z",
     "start_time": "2023-09-02T13:40:54.653687Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rouge = Rouge()\n",
    "\n",
    "def compute_metric(evalPred):\n",
    "    predictions, labels = evalPred\n",
    "    # 有\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    decoded_preds = [\" \".join(p) for p in decoded_preds]\n",
    "    decoded_labels = [\" \".join(p) for p in decoded_labels]\n",
    "    scores = rouge.get_scores(decoded_preds, decoded_labels, avg=True)\n",
    "    return {\n",
    "        \"rouge-1\": scores[\"rouge-1\"][\"f\"],\n",
    "        \"rouge-2\": scores[\"rouge-2\"][\"f\"],\n",
    "        \"rouge-l\": scores[\"rouge-l\"][\"f\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154385ec601e5896",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 6: 设置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1391403a28f12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T13:40:56.575940Z",
     "start_time": "2023-09-02T13:40:56.552389Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 配置训练参数\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./summary\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8,\n",
    "    logging_steps=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"rouge-l\",\n",
    "    predict_with_generate=True,  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f9df45b019f855",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 7: 设置训练器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11564d981db9b3f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T13:41:13.322531Z",
     "start_time": "2023-09-02T13:41:13.273427Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    args=args,\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    compute_metrics=compute_metric,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a6cd4b4fc7f8cd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 8: 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe3478ff9ba128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T14:04:51.761298Z",
     "start_time": "2023-09-02T13:41:15.645589Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebd7f8cf6a9db3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Step 9: 模型推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e0d96d26073e51",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4a3e245648a4c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a901eac2c71e8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pipe(\"摘要生成:\\n\" + dataset[\"test\"][-1][\"Content\"], max_length=64, do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe13fe3f906ad3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset[\"test\"][-1][\"title\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
